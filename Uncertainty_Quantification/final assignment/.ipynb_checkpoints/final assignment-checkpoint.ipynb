{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_bvp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic collocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BVP solver (convert heateqn.m to python code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define f(Z)\n",
    "def f(x, Z):\n",
    "    f = np.sin(Z*x - 0.2)\n",
    "    return f\n",
    "\n",
    "def bc(ya, yb):\n",
    "    return np.array([ya[0], yb[0]])\n",
    "\n",
    "def BVP_solver(x, y, Z, x_s):\n",
    "        \n",
    "    pde = lambda x, y: [y[1], -f(Z, x)]\n",
    "\n",
    "    # Apply scipy.solve_bvp to solve boundary value problem\n",
    "    sol = solve_bvp(pde, bc, x, y)\n",
    "\n",
    "    y_plot = sol.sol(x_s)[0]\n",
    "\n",
    "    return y_plot\n",
    "\n",
    "'''Evaluate the BVP solver'''\n",
    "\n",
    "xs = np.linspace(-1, 1, 100)\n",
    "y_bc = np.zeros((2, xs.size))\n",
    "Z_initial = np.random.uniform(2, 16, size=1000)\n",
    "y_initial = np.zeros((len(Z_initial), len(xs)))\n",
    "\n",
    "for i in range(len(Z_initial)): \n",
    "    y_plot = BVP_solver(xs, y_bc, Z_initial[i], xs)\n",
    "    y_initial[i, :] = y_plot\n",
    "    plt.plot(xs, y_plot)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('u value')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Compute nodes and weights for Clenshaw-Curtis quadrature rule (convert clensurt.m to python code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def clenshaw_curtis_compute ( n ):\n",
    "  #*****************************************************************************80\n",
    "#\n",
    "## CLENSHAW_CURTIS_COMPUTE computes a Clenshaw Curtis quadrature rule.\n",
    "#\n",
    "#  Discussion:\n",
    "#\n",
    "#    This method uses a direct approach.  The paper by Waldvogel\n",
    "#    exhibits a more efficient approach using Fourier transforms.\n",
    "#\n",
    "#    The integral:\n",
    "#\n",
    "#      integral ( -1 <= x <= 1 ) f(x) dx\n",
    "#\n",
    "#    The quadrature rule:\n",
    "#\n",
    "#      sum ( 1 <= i <= n ) w(i) * f ( x(i) )\n",
    "#\n",
    "#    The abscissas for the rule of order N can be regarded\n",
    "#    as the cosines of equally spaced angles between 180 and 0 degrees:\n",
    "#\n",
    "#      X(I) = cos ( ( N - I ) * PI / ( N - 1 ) )\n",
    "#\n",
    "#    except for the basic case N = 1, when\n",
    "#\n",
    "#      X(1) = 0.\n",
    "#\n",
    "#    A Clenshaw-Curtis rule that uses N points will integrate\n",
    "#    exactly all polynomials of degrees 0 through N-1.  If N\n",
    "#    is odd, then by symmetry the polynomial of degree N will\n",
    "#    also be integrated exactly.\n",
    "#\n",
    "#    If the value of N is increased in a sensible way, then\n",
    "#    the new set of abscissas will include the old ones.  One such\n",
    "#    sequence would be N(K) = 2*K+1 for K = 0, 1, 2, ...\n",
    "#\n",
    "#  Licensing:\n",
    "#\n",
    "#    This code is distributed under the GNU LGPL license.\n",
    "#\n",
    "#  Modified:\n",
    "#\n",
    "#    02 April 2015\n",
    "#\n",
    "#  Author:\n",
    "#\n",
    "#    John Burkardt\n",
    "#\n",
    "#  Reference:\n",
    "#\n",
    "#    Charles Clenshaw, Alan Curtis,\n",
    "#    A Method for Numerical Integration on an Automatic Computer,\n",
    "#    Numerische Mathematik,\n",
    "#    Volume 2, Number 1, December 1960, pages 197-205.\n",
    "#\n",
    "#    Philip Davis, Philip Rabinowitz,\n",
    "#    Methods of Numerical Integration,\n",
    "#    Second Edition,\n",
    "#    Dover, 2007,\n",
    "#    ISBN: 0486453391,\n",
    "#    LC: QA299.3.D28.\n",
    "#\n",
    "#    Joerg Waldvogel,\n",
    "#    Fast Construction of the Fejer and Clenshaw-Curtis Quadrature Rules,\n",
    "#    BIT Numerical Mathematics,\n",
    "#    Volume 43, Number 1, 2003, pages 1-18.\n",
    "#\n",
    "#  Parameters:\n",
    "#\n",
    "#    Input, integer N, the order.\n",
    "#\n",
    "#    Output, real X(N), the abscissas.\n",
    "#\n",
    "#    Output, real W(N), the weights.\n",
    "#\n",
    "  if ( n == 1 ):\n",
    "\n",
    "    x = np.zeros ( n )\n",
    "    w = np.zeros ( n )\n",
    "\n",
    "    w[0] = 2.0\n",
    "\n",
    "  else:\n",
    "\n",
    "    theta = np.zeros ( n )\n",
    "\n",
    "    for i in range ( 0, n ):\n",
    "      theta[i] = float ( n - 1 - i ) * np.pi / float ( n - 1 )\n",
    "\n",
    "    x = np.cos ( theta )\n",
    "    w = np.zeros ( n )\n",
    "\n",
    "    for i in range ( 0, n ):\n",
    "\n",
    "      w[i] = 1.0\n",
    "\n",
    "      jhi = ( ( n - 1 ) // 2 )\n",
    "\n",
    "      for j in range ( 0, jhi ):\n",
    "\n",
    "        if ( 2 * ( j + 1 ) == ( n - 1 ) ):\n",
    "          b = 1.0\n",
    "        else:\n",
    "          b = 2.0\n",
    "\n",
    "        w[i] = w[i] - b * np.cos ( 2.0 * float ( j + 1 ) * theta[i] ) \\\n",
    "             / float ( 4 * j * ( j + 2 ) + 3 )\n",
    "\n",
    "    w[0] = w[0] / float ( n - 1 )\n",
    "    for i in range ( 1, n - 1 ):\n",
    "      w[i] = 2.0 * w[i] / float ( n - 1 )\n",
    "    w[n-1] = w[n-1] / float ( n - 1 )\n",
    "\n",
    "  return x, w\n",
    "\n",
    "x, w = clenshaw_curtis_compute(14)\n",
    "x = np.round(x*1000)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the Lagrange interpolation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lagrange interpolation\n",
    "def Lagrange_interpolation(xp, x, y):\n",
    "    # xp is the evaluate point, x, y are the given data points\n",
    "    yp = 0\n",
    "    for i in range(len(x)):\n",
    "        p = 1\n",
    "\n",
    "        for j in range(len(x)):\n",
    "            if i != j:\n",
    "                p = p * (xp - x[j])/(x[i] - x[j])\n",
    "        \n",
    "        yp = yp + p * y[i]  \n",
    "    return yp  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Stochastic collocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Compute the equation value correponding to Clen-Curtis nodes'''\n",
    "# Compute the Clenshaw-Curtis nodes\n",
    "M = 20\n",
    "x_c, w_c = clenshaw_curtis_compute(M)\n",
    "\n",
    "# Define the evaluation points\n",
    "xs = np.linspace(-1, 1, 2000)\n",
    "Z = np.random.uniform(2, 16, size=1000)\n",
    "\n",
    "# Define the boundary conditions\n",
    "y_bc = np.zeros((2, xs.size))\n",
    "\n",
    "# y_true is a matrix with len(Z) rows and len(x_c) columns\n",
    "# Used for storing true values of the ODE solutions corresponding to different Z and x_c\n",
    "y_true = np.zeros((len(Z), len(x_c)))\n",
    "\n",
    "# Compute the equation value corresponding to Clenshaw-Curtis nodes with 1000 Z values\n",
    "for i in range(len(Z)):\n",
    "    y_true[i,:] = BVP_solver(xs, y_bc, Z[i], x_c)\n",
    "\n",
    "\n",
    "\n",
    "'''Lagrange interpolation of y_true and x_c'''\n",
    "\n",
    "x_inter = np.linspace(-1, 1, 100)\n",
    "y_inter = np.zeros((len(Z), len(x_inter)))\n",
    "\n",
    "for i in range(len(Z)):\n",
    "    for j in range(len(x_inter)):\n",
    "        y_inter[i, j] = Lagrange_interpolation(x_inter[j], x_c, y_true[i, :])\n",
    "\n",
    "for i in range(len(y_inter)):\n",
    "    plt.plot(x_inter, y_inter[i])\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('u value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick interpolation value of x=0.7\n",
    "x_index = np.where(np.round(x_inter*100)==70)\n",
    "y_eva = y_inter[:, x_index]\n",
    "y_eva = np.ndarray.flatten(y_eva)\n",
    "\n",
    "y_eva_i = y_initial[:, x_index]\n",
    "y_eva_i = np.ndarray.flatten(y_eva_i)\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.plot(Z, y_eva, 'r.', label='approximation')\n",
    "plt.plot(Z_initial, y_eva_i, 'b.', label='true value')\n",
    "plt.xlabel('Z')\n",
    "plt.ylabel('u')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.hist(y_eva, 50, label='approximation')\n",
    "plt.hist(y_eva_i, 50, label='true value')\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('number of points')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_initial_mean = np.mean(y_initial, axis=0)\n",
    "y_initial_std = np.std(y_initial, axis=0)\n",
    "y_eva_mean = np.mean(y_inter, axis=0)\n",
    "y_eva_std = np.std(y_inter, axis=0)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(x_inter, y_initial_mean, label='true value')\n",
    "plt.plot(x_inter, y_eva_mean, label='approximation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('u')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(x_inter, y_initial_std, label='true value')\n",
    "plt.plot(x_inter, y_eva_std, label='approximation')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('u')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. initial settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the original function\n",
    "def f_water(r_w, r, T_u, H_u, T_l, H_l, L, K_w):\n",
    "\n",
    "    # Compute the original function\n",
    "    mid = np.log(r/r_w) \n",
    "    f = (2*np.pi*T_u * (H_u-H_l)) / (mid * (1 + (2*L*T_u) / (mid * r_w**2 * K_w) + T_u/T_l))\n",
    "\n",
    "    return f\n",
    "\n",
    "# Build C matrix for satelli's Algorithm\n",
    "def C_i_convert(A, B):\n",
    "\n",
    "    size = len(A[0])\n",
    "    C_i = [None] * size\n",
    "\n",
    "    # Replace i-th column in B with i-th column in A, generate C_i\n",
    "    for i in range(size):\n",
    "        B_ = B.copy()\n",
    "        B_[:,i] = A[:,i]\n",
    "        C_i[i] = B_\n",
    "\n",
    "    # Note C is a list, C[i] containes C_i in Satellis' algorithm\n",
    "    return C_i\n",
    "\n",
    "# Define the first-order Sobol indice estimator and total effects Sobol indices\n",
    "def Sobol_indices_estimator(A, B, C_i, f):\n",
    "    '''take matrix A, C and function f(x) as input, generate first-ordere Sobol indices S_i'''\n",
    "\n",
    "    # M is the number of MC samples\n",
    "    M = len(A)\n",
    "    # n is the number of random variables\n",
    "    n = len(A[0])\n",
    "\n",
    "    # Compute y_A, y_B, y_A and y_B are 1 x M arrays\n",
    "    y_A = f(A[:,0], A[:,1], A[:,2], A[:,3], A[:,4], A[:,5], A[:,6], A[:,7])\n",
    "    y_B = f(B[:,0], B[:,1], B[:,2], B[:,3], B[:,4], B[:,5], B[:,6], B[:,7])\n",
    "\n",
    "    # Compute f0^2\n",
    "    mean_A = np.mean(y_A)\n",
    "    mean_B = np.mean(y_B)\n",
    "    f02 = mean_A*mean_B\n",
    "\n",
    "    # Compute y_C, y_C is a n x M matrix\n",
    "    y_C = np.zeros((n, M))\n",
    "    for i in range(n):\n",
    "        C = C_i[i]\n",
    "        y_C[i,:] = f(C[:,0], C[:,1], C[:,2], C[:,3], C[:,4], C[:,5], C[:,6], C[:,7])\n",
    "    \n",
    "    # Compute S_i and S_Ti, S_i and S_Ti are 1 x n arrays\n",
    "    S_i = np.zeros(n)\n",
    "    S_Ti = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        S_i[i] = ((1/M) * (y_A @ y_C[i]) - f02) / ((1/M) * (y_A @ y_A) - f02)\n",
    "        S_Ti[i] = 1 - ((1/M) * (y_B @ y_C[i]) - f02) / ((1/M) * (y_A @ y_A) - f02)\n",
    "\n",
    "    return S_i, S_Ti\n",
    "\n",
    "# TEST\n",
    "# A = np.array([[1,1], [1,1]])\n",
    "# B = np.array([[0,0], [0,0]])\n",
    "# C = C_convert(A, B)\n",
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_w, r, T_u, H_u, T_l, H_l, L, K_w\n",
    "# MC size\n",
    "M = int(1e6)\n",
    "\n",
    "# Generate random variables input\n",
    "r_w = np.random.normal(0.2, 0.016, size=M)\n",
    "r = np.random.lognormal(7.7, 1.0, size=M)\n",
    "T_u = np.random.uniform(63000, 116000, size=M)\n",
    "H_u = np.random.uniform(1000, 1130, size=M)\n",
    "T_l = np.random.uniform(63, 116, size=M)\n",
    "H_l = np.random.uniform(700, 820, size=M)\n",
    "L = np.random.normal(1400, 100, size=M)\n",
    "K_w = np.random.uniform(9900, 12100, size=M)\n",
    "\n",
    "r_w_b = np.random.normal(0.2, 0.016, size=M)\n",
    "r_b = np.random.lognormal(7.7, 1.0, size=M)\n",
    "T_u_b = np.random.uniform(63000, 116000, size=M)\n",
    "H_u_b = np.random.uniform(1000, 1130, size=M)\n",
    "T_l_b = np.random.uniform(63, 116, size=M)\n",
    "H_l_b = np.random.uniform(700, 820, size=M)\n",
    "L_b = np.random.normal(1400, 100, size=M)\n",
    "K_w_b = np.random.uniform(9900, 12100, size=M)\n",
    "\n",
    "\n",
    "# Construct matrix A and B, note the sequence of random variables is very important!\n",
    "A = np.transpose(np.array([r_w, r, T_u, H_u, T_l, H_l, L, K_w]))\n",
    "B = np.transpose(np.array([r_w_b, r_b, T_u_b, H_u_b, T_l_b, H_l_b, L_b, K_w_b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimate Sobol indices by Satelli's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create C_i\n",
    "C = C_i_convert(A, B)\n",
    "\n",
    "S_i, S_Ti = Sobol_indices_estimator(A, B, C, f_water)\n",
    "\n",
    "print(S_i, S_Ti)\n",
    "\n",
    "f_mean_var = f_water(r_w, r, T_u, H_u, T_l, H_l, L, K_w)\n",
    "var_f = np.var(f_mean_var)\n",
    "mean_f = np.mean(f_mean_var)\n",
    "var_f, mean_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3_plot_x = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "plt.plot(q3_plot_x, S_i, 'b--', label=r'$S_i$')\n",
    "plt.plot(q3_plot_x, S_Ti, 'y--', label=r'$S_{Ti}$')\n",
    "\n",
    "plt.plot(q3_plot_x, S_i, 'b.')\n",
    "plt.plot(q3_plot_x, S_Ti, 'y.')\n",
    "\n",
    "plt.xlabel('i', fontsize=15)\n",
    "plt.ylabel('Sobol indices', fontsize=15)\n",
    "\n",
    "plt.legend(loc=1, prop={'size': 20})\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generalized Satelli's algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def second_order_estimator(A, B, f, i=4, j=6):\n",
    "    '''take matrix A, C and function f(x) as input, generate first-ordere Sobol indices S_i'''\n",
    "\n",
    "    # M is the number of MC samples\n",
    "    M = len(A)\n",
    "    # n is the number of random variables\n",
    "    n = len(A[0])\n",
    "\n",
    "    Ab_i = A.copy()\n",
    "    Ab_i[:,i] = B[:,i]\n",
    "    Ab_j = A.copy()\n",
    "    Ab_j[:,j] = B[:,j]\n",
    "\n",
    "    f_value = 0\n",
    "    for k in range(M):\n",
    "\n",
    "        inside = f(Ab_i[k,0], Ab_i[k,1], Ab_i[k,2], Ab_i[k,3], Ab_i[k,4], Ab_i[k,5], Ab_i[k,6], Ab_i[k,7]) - \\\n",
    "                 f(Ab_j[k,0], Ab_j[k,1], Ab_j[k,2], Ab_j[k,3], Ab_j[k,4], Ab_j[k,5], Ab_j[k,6], Ab_j[k,7])\n",
    "\n",
    "        f_value_ = inside**2\n",
    "        f_value += f_value_\n",
    "    \n",
    "    Vij = f_value / (2*M)\n",
    "\n",
    "    return Vij\n",
    "\n",
    "Vij = second_order_estimator(A, B, f_water)\n",
    "print(Vij)\n",
    "Sv = Vij / var_f + S_i[3] + S_i[5]\n",
    "Sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bayesian Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the original function\n",
    "def f(alpha, beta):\n",
    "    f = 1.5*alpha + 0.25*(beta-1)**2 + np.cos(np.pi+alpha+beta)\n",
    "    return f\n",
    "\n",
    "# Define prior distribution: N ~ (u, \\theta^2 * I), u = (1, 1), \\theta = 0.25, I = idendity matrix\n",
    "def prior(x):\n",
    "    '''Note that x is a vector of random variables, the prior distribution is all about random\n",
    "       variables Z! Not f(Z)!\n",
    "    '''\n",
    "    mean = np.array([1,1])\n",
    "    theta = 0.25\n",
    "    # k is the number of random variables\n",
    "    k = len(x)\n",
    "\n",
    "    # Compute the covariance matrix\n",
    "    cov_matrix = theta**2 * np.identity(len(mean))\n",
    "\n",
    "    # Compute the probability density function\n",
    "    prob = np.exp(-(1/2) * (x-mean) @ np.linalg.inv(cov_matrix) @ (x-mean)) / \\\n",
    "           ((2*np.pi)**k * np.linalg.det(cov_matrix))**0.5\n",
    "\n",
    "    return prob\n",
    "\n",
    "# Define the likelihood distribution density function\n",
    "def likelihood(x, data):\n",
    "    '''y_i = f(alpha, beta) + gamma*r_i, where gamma*r_i is the noise term, r_i is N ~ (0, 1), so\n",
    "       the gamma*r_i is N ~ (0, gamma^2)\n",
    "    '''\n",
    "    gamma = 0.1\n",
    "    f_value = f(x[0], x[1])\n",
    "    \n",
    "    # calculate the likelihood density\n",
    "    prob_li = np.exp(-(1/(2*gamma**2)) * sum((data[i] - f_value)**2 for i in range(len(data))))\n",
    "\n",
    "    return prob_li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Marcov Chain Monte Carlo Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the given noisy data and initial settings\n",
    "data = np.array([4.02, 3.97, 4.05, 3.85, 3.94])\n",
    "\n",
    "# Set iteration number\n",
    "ite = 2000\n",
    "\n",
    "# Set the covariance matrix for proposal distribution\n",
    "a = 0.1**2 * np.identity(2)\n",
    "\n",
    "# Store the alpha,beta at each iteration step\n",
    "alphabeta = np.zeros((2, ite))\n",
    "accept = 0\n",
    "\n",
    "# set the start point for Markov Chain\n",
    "alphabeta[:, 0] = [3, 3]\n",
    "c = 0\n",
    "\n",
    "for i in range(ite-1):\n",
    "\n",
    "    # Generate next alpha, beta from proposal distribution\n",
    "    alpha_next, beta_next = np.random.multivariate_normal(alphabeta[:, i].T, a)\n",
    "\n",
    "    # compute the value for p(d|Z)*p(Z) and p(d|f_next)*p(f_next)\n",
    "    pf = prior(alphabeta[:, i])\n",
    "    #print(pf)\n",
    "    pdf = likelihood(alphabeta[:, i], data=data)\n",
    "    #print(pdf)\n",
    "    pf_next = prior([alpha_next, beta_next])\n",
    "    pdf_next = likelihood([alpha_next, beta_next], data=data)\n",
    "\n",
    "    # Calculate the accepte prabobility\n",
    "    accepte_prob = min(1, pf_next*pdf_next / (pf*pdf))\n",
    "\n",
    "    # Accept the sample point with the calculated probability\n",
    "    if np.random.random() < accepte_prob:\n",
    "        alphabeta[:, i+1] = [alpha_next, beta_next]\n",
    "        accept += 1\n",
    "\n",
    "    # Otherwise report the current sample point again\n",
    "    else:\n",
    "        alphabeta[:, i+1] = alphabeta[:, i]\n",
    "    \n",
    "    if i % 20 == 0:\n",
    "        print(i, end= ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accep_rate = accept/ite\n",
    "print(accep_rate)\n",
    "\n",
    "alpha_plot, beta_plot = np.random.multivariate_normal(mean=[1, 1], cov=[[0.0625, 0], [0, 0.0625]], size=500).T\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(alpha_plot, beta_plot, 'b.', label='Prior distribution')\n",
    "# plt.quiver(alphabeta[0,:-1], alphabeta[1,:-1], alphabeta[0,1:]-alphabeta[0,:-1], alphabeta[1,1:]-alphabeta[1,:-1], \\\n",
    "           # scale_units='xy', angles='xy', scale=1, color='r', width=0.002, headwidth=3, headlength=2, zorder=2)\n",
    "\n",
    "plt.plot(alphabeta[0, :], alphabeta[1, :], 'r.', label='Posterior distribution')\n",
    "\n",
    "plt.xlabel(r'$\\alpha$', fontsize=15)\n",
    "plt.ylabel(r'$\\beta$', fontsize=15)\n",
    "plt.title('acceptance rate = ' + str(accep_rate), fontsize=15)\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "plt.legend(loc=2, prop={'size': 15})\n",
    "plt.show()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.hist(alphabeta[0,:], 50, label=r'$\\alpha$')\n",
    "plt.hist(alphabeta[1,:], 50, label=r'$\\beta$')\n",
    "plt.xlabel('value', fontsize=15)\n",
    "plt.ylabel('number of points', fontsize=15)\n",
    "plt.legend(loc=1, prop={'size': 15})\n",
    "plt.show()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(alphabeta[0,:], 'b', label=r'$\\alpha$')\n",
    "plt.plot(alphabeta[1,:], 'r', label=r'$\\beta$')\n",
    "plt.xlabel('iteration', fontsize=15)\n",
    "plt.ylabel('value', fontsize=15)\n",
    "plt.legend(loc=1, prop={'size': 15})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_eva = f(alphabeta[0,:], alphabeta[1,:])\n",
    "\n",
    "print(np.mean(f_eva))\n",
    "\n",
    "mean_data = np.ones(ite) * np.mean(data)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.plot(f_eva, 'r', label='function value')\n",
    "plt.plot(mean_data, 'b', label='mean of noisy data')\n",
    "plt.xlabel('iteration', fontsize=15)\n",
    "plt.ylabel('value', fontsize=15)\n",
    "plt.legend(loc=1, prop={'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5fdd5d292a9b6f34e0661329dc70a90de1dc19326df9dbf72be382a0607df2b1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
